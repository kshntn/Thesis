{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten,Conv1D,MaxPooling1D\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= np.loadtxt('norm.csv', delimiter=',', dtype='float32')\n",
    "label=np.loadtxt('encodedlabel.csv',delimiter=',',dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((900, 14), (900, 3), (232, 14), (232, 3))\n"
     ]
    }
   ],
   "source": [
    "train_data=data[0:900,:]\n",
    "test_data=data[900:,:]\n",
    "train_label=label[0:900,:]\n",
    "test_label=label[900:,:]\n",
    "print(train_data.shape, train_label.shape,test_data.shape, test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input1=Input(shape=(14,1))\n",
    "enc1=Dense(10,activation='relu')(input1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 720 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "720/720 [==============================] - 0s 489us/step - loss: 0.1013 - val_loss: 0.1054\n",
      "(900, 7)\n"
     ]
    }
   ],
   "source": [
    "# layer 1\n",
    "input_1= Input(shape=(14,))\n",
    "enc_1= Dense(7, activation='relu')(input_1)\n",
    "dec_1=Dense(14, activation='relu')(enc_1)\n",
    "\n",
    "autoenc_1= Model(input_1, dec_1)\n",
    "encoder_1= Model(input_1, enc_1)\n",
    "\n",
    "autoenc_1.compile(optimizer='adam', loss='mean_squared_error')\n",
    "autoenc_1.fit(train_data,train_data,epochs=1,validation_split=0.2)\n",
    "\n",
    "\n",
    "ly1_predict= encoder_1.predict(train_data)\n",
    "print(ly1_predict.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 720 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "720/720 [==============================] - 0s 535us/step - loss: 0.0625 - val_loss: 0.0787\n",
      "(900, 5)\n"
     ]
    }
   ],
   "source": [
    "# layer 2\n",
    "input_2= Input(shape=(7,))\n",
    "enc_2= Dense(5, activation='relu')(input_2)\n",
    "dec_2=Dense(7, activation='relu')(enc_2)\n",
    "\n",
    "autoenc_2= Model(input_2, dec_2)\n",
    "encoder_2= Model(input_2, enc_2)\n",
    "\n",
    "autoenc_2.compile(optimizer='adam', loss='mean_squared_error')\n",
    "autoenc_2.fit(ly1_predict,ly1_predict,epochs=1,validation_split=0.2)\n",
    "\n",
    "\n",
    "ly2_predict= encoder_2.predict(ly1_predict)\n",
    "print(ly2_predict.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 720 samples, validate on 180 samples\n",
      "Epoch 1/1\n",
      "720/720 [==============================] - 0s 538us/step - loss: 0.0101 - val_loss: 0.0080\n",
      "(900, 3)\n"
     ]
    }
   ],
   "source": [
    "# layer 3\n",
    "input_3= Input(shape=(5,))\n",
    "enc_3= Dense(3, activation='relu')(input_3)\n",
    "dec_3=Dense(5, activation='relu')(enc_3)\n",
    "\n",
    "autoenc_3= Model(input_3, dec_3)\n",
    "encoder_3= Model(input_3, enc_3)\n",
    "\n",
    "autoenc_3.compile(optimizer='adam', loss='mean_squared_error')\n",
    "autoenc_3.fit(ly2_predict,ly2_predict,epochs=1,validation_split=0.2)\n",
    "\n",
    "\n",
    "ly3_predict= encoder_3.predict(ly2_predict)\n",
    "print(ly3_predict.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 720 samples, validate on 180 samples\n",
      "Epoch 1/50\n",
      "720/720 [==============================] - 1s 819us/step - loss: 0.1167 - acc: 0.0653 - val_loss: 0.1223 - val_acc: 0.5556\n",
      "Epoch 2/50\n",
      "720/720 [==============================] - 0s 132us/step - loss: 0.1075 - acc: 0.5833 - val_loss: 0.1081 - val_acc: 0.5556\n",
      "Epoch 3/50\n",
      "720/720 [==============================] - 0s 131us/step - loss: 0.0893 - acc: 0.5528 - val_loss: 0.0906 - val_acc: 0.1333\n",
      "Epoch 4/50\n",
      "720/720 [==============================] - 0s 122us/step - loss: 0.0754 - acc: 0.1556 - val_loss: 0.0804 - val_acc: 0.1333\n",
      "Epoch 5/50\n",
      "720/720 [==============================] - 0s 122us/step - loss: 0.0682 - acc: 0.1542 - val_loss: 0.0759 - val_acc: 0.1333\n",
      "Epoch 6/50\n",
      "720/720 [==============================] - 0s 127us/step - loss: 0.0653 - acc: 0.1625 - val_loss: 0.0742 - val_acc: 0.2944\n",
      "Epoch 7/50\n",
      "720/720 [==============================] - 0s 121us/step - loss: 0.0642 - acc: 0.5111 - val_loss: 0.0736 - val_acc: 0.5556\n",
      "Epoch 8/50\n",
      "720/720 [==============================] - 0s 162us/step - loss: 0.0637 - acc: 0.5833 - val_loss: 0.0732 - val_acc: 0.5556\n",
      "Epoch 9/50\n",
      "720/720 [==============================] - 0s 130us/step - loss: 0.0634 - acc: 0.5833 - val_loss: 0.0730 - val_acc: 0.5556\n",
      "Epoch 10/50\n",
      "720/720 [==============================] - 0s 130us/step - loss: 0.0632 - acc: 0.5833 - val_loss: 0.0728 - val_acc: 0.5556\n",
      "Epoch 11/50\n",
      "720/720 [==============================] - 0s 140us/step - loss: 0.0630 - acc: 0.5833 - val_loss: 0.0726 - val_acc: 0.5556\n",
      "Epoch 12/50\n",
      "720/720 [==============================] - 0s 156us/step - loss: 0.0629 - acc: 0.5833 - val_loss: 0.0724 - val_acc: 0.5556\n",
      "Epoch 13/50\n",
      "720/720 [==============================] - 0s 145us/step - loss: 0.0624 - acc: 0.5833 - val_loss: 0.0717 - val_acc: 0.5556\n",
      "Epoch 14/50\n",
      "720/720 [==============================] - 0s 129us/step - loss: 0.0620 - acc: 0.5833 - val_loss: 0.0713 - val_acc: 0.5556\n",
      "Epoch 15/50\n",
      "720/720 [==============================] - 0s 153us/step - loss: 0.0616 - acc: 0.5833 - val_loss: 0.0710 - val_acc: 0.5556\n",
      "Epoch 16/50\n",
      "720/720 [==============================] - 0s 130us/step - loss: 0.0611 - acc: 0.5833 - val_loss: 0.0702 - val_acc: 0.5556\n",
      "Epoch 17/50\n",
      "720/720 [==============================] - 0s 132us/step - loss: 0.0592 - acc: 0.5861 - val_loss: 0.0648 - val_acc: 0.5611\n",
      "Epoch 18/50\n",
      "720/720 [==============================] - 0s 132us/step - loss: 0.0558 - acc: 0.6236 - val_loss: 0.0596 - val_acc: 0.6278\n",
      "Epoch 19/50\n",
      "720/720 [==============================] - 0s 124us/step - loss: 0.0538 - acc: 0.6292 - val_loss: 0.0578 - val_acc: 0.6278\n",
      "Epoch 20/50\n",
      "720/720 [==============================] - 0s 118us/step - loss: 0.0530 - acc: 0.6292 - val_loss: 0.0568 - val_acc: 0.6278\n",
      "Epoch 21/50\n",
      "720/720 [==============================] - 0s 160us/step - loss: 0.0524 - acc: 0.6292 - val_loss: 0.0560 - val_acc: 0.6278\n",
      "Epoch 22/50\n",
      "720/720 [==============================] - 0s 130us/step - loss: 0.0517 - acc: 0.6292 - val_loss: 0.0551 - val_acc: 0.6278\n",
      "Epoch 23/50\n",
      "720/720 [==============================] - 0s 126us/step - loss: 0.0512 - acc: 0.6278 - val_loss: 0.0544 - val_acc: 0.6111\n",
      "Epoch 24/50\n",
      "720/720 [==============================] - 0s 130us/step - loss: 0.0506 - acc: 0.6181 - val_loss: 0.0537 - val_acc: 0.5889\n",
      "Epoch 25/50\n",
      "720/720 [==============================] - 0s 124us/step - loss: 0.0501 - acc: 0.6028 - val_loss: 0.0532 - val_acc: 0.5889\n",
      "Epoch 26/50\n",
      "720/720 [==============================] - 0s 134us/step - loss: 0.0497 - acc: 0.5958 - val_loss: 0.0527 - val_acc: 0.5889\n",
      "Epoch 27/50\n",
      "720/720 [==============================] - 0s 146us/step - loss: 0.0493 - acc: 0.5847 - val_loss: 0.0523 - val_acc: 0.5611\n",
      "Epoch 28/50\n",
      "720/720 [==============================] - 0s 144us/step - loss: 0.0489 - acc: 0.5792 - val_loss: 0.0519 - val_acc: 0.5556\n",
      "Epoch 29/50\n",
      "720/720 [==============================] - 0s 127us/step - loss: 0.0486 - acc: 0.5778 - val_loss: 0.0515 - val_acc: 0.5500\n",
      "Epoch 30/50\n",
      "720/720 [==============================] - 0s 127us/step - loss: 0.0483 - acc: 0.5722 - val_loss: 0.0513 - val_acc: 0.5500\n",
      "Epoch 31/50\n",
      "720/720 [==============================] - 0s 136us/step - loss: 0.0480 - acc: 0.5694 - val_loss: 0.0509 - val_acc: 0.5389\n",
      "Epoch 32/50\n",
      "720/720 [==============================] - 0s 143us/step - loss: 0.0477 - acc: 0.5653 - val_loss: 0.0507 - val_acc: 0.5389\n",
      "Epoch 33/50\n",
      "720/720 [==============================] - 0s 141us/step - loss: 0.0475 - acc: 0.5569 - val_loss: 0.0505 - val_acc: 0.5389\n",
      "Epoch 34/50\n",
      "720/720 [==============================] - 0s 118us/step - loss: 0.0472 - acc: 0.5528 - val_loss: 0.0503 - val_acc: 0.5389\n",
      "Epoch 35/50\n",
      "720/720 [==============================] - 0s 149us/step - loss: 0.0470 - acc: 0.5542 - val_loss: 0.0501 - val_acc: 0.5389\n",
      "Epoch 36/50\n",
      "720/720 [==============================] - 0s 134us/step - loss: 0.0468 - acc: 0.5583 - val_loss: 0.0499 - val_acc: 0.5389\n",
      "Epoch 37/50\n",
      "720/720 [==============================] - 0s 131us/step - loss: 0.0466 - acc: 0.5500 - val_loss: 0.0497 - val_acc: 0.5389\n",
      "Epoch 38/50\n",
      "720/720 [==============================] - 0s 148us/step - loss: 0.0464 - acc: 0.5472 - val_loss: 0.0495 - val_acc: 0.5389\n",
      "Epoch 39/50\n",
      "720/720 [==============================] - 0s 145us/step - loss: 0.0463 - acc: 0.5569 - val_loss: 0.0493 - val_acc: 0.5389\n",
      "Epoch 40/50\n",
      "720/720 [==============================] - 0s 140us/step - loss: 0.0461 - acc: 0.5500 - val_loss: 0.0491 - val_acc: 0.5389\n",
      "Epoch 41/50\n",
      "720/720 [==============================] - 0s 124us/step - loss: 0.0459 - acc: 0.5500 - val_loss: 0.0490 - val_acc: 0.5389\n",
      "Epoch 42/50\n",
      "720/720 [==============================] - 0s 142us/step - loss: 0.0457 - acc: 0.5653 - val_loss: 0.0487 - val_acc: 0.5444\n",
      "Epoch 43/50\n",
      "720/720 [==============================] - 0s 142us/step - loss: 0.0455 - acc: 0.5583 - val_loss: 0.0486 - val_acc: 0.5389\n",
      "Epoch 44/50\n",
      "720/720 [==============================] - 0s 148us/step - loss: 0.0453 - acc: 0.5736 - val_loss: 0.0483 - val_acc: 0.5500\n",
      "Epoch 45/50\n",
      "720/720 [==============================] - 0s 125us/step - loss: 0.0451 - acc: 0.5736 - val_loss: 0.0481 - val_acc: 0.5500\n",
      "Epoch 46/50\n",
      "720/720 [==============================] - 0s 149us/step - loss: 0.0448 - acc: 0.5764 - val_loss: 0.0479 - val_acc: 0.5556\n",
      "Epoch 47/50\n",
      "720/720 [==============================] - 0s 124us/step - loss: 0.0446 - acc: 0.5722 - val_loss: 0.0477 - val_acc: 0.5556\n",
      "Epoch 48/50\n",
      "720/720 [==============================] - 0s 116us/step - loss: 0.0444 - acc: 0.5778 - val_loss: 0.0475 - val_acc: 0.5556\n",
      "Epoch 49/50\n",
      "720/720 [==============================] - 0s 131us/step - loss: 0.0442 - acc: 0.5778 - val_loss: 0.0473 - val_acc: 0.5556\n",
      "Epoch 50/50\n",
      "720/720 [==============================] - 0s 133us/step - loss: 0.0441 - acc: 0.5861 - val_loss: 0.0471 - val_acc: 0.5667\n",
      "Train on 720 samples, validate on 180 samples\n",
      "Epoch 1/25\n",
      "720/720 [==============================] - 1s 793us/step - loss: 0.2636 - acc: 0.5069 - val_loss: 0.2420 - val_acc: 0.5278\n",
      "Epoch 2/25\n",
      "720/720 [==============================] - 0s 141us/step - loss: 0.2223 - acc: 0.5125 - val_loss: 0.2132 - val_acc: 0.5333\n",
      "Epoch 3/25\n",
      "720/720 [==============================] - 0s 174us/step - loss: 0.1864 - acc: 0.5153 - val_loss: 0.1869 - val_acc: 0.5333\n",
      "Epoch 4/25\n",
      "720/720 [==============================] - 0s 112us/step - loss: 0.1571 - acc: 0.6083 - val_loss: 0.1638 - val_acc: 0.7333\n",
      "Epoch 5/25\n",
      "720/720 [==============================] - 0s 108us/step - loss: 0.1326 - acc: 0.8319 - val_loss: 0.1442 - val_acc: 0.8111\n",
      "Epoch 6/25\n",
      "720/720 [==============================] - 0s 107us/step - loss: 0.1131 - acc: 0.8639 - val_loss: 0.1341 - val_acc: 0.7889\n",
      "Epoch 7/25\n",
      "720/720 [==============================] - 0s 130us/step - loss: 0.1005 - acc: 0.8458 - val_loss: 0.1265 - val_acc: 0.7667\n",
      "Epoch 8/25\n",
      "720/720 [==============================] - 0s 118us/step - loss: 0.0916 - acc: 0.8472 - val_loss: 0.1192 - val_acc: 0.7944\n",
      "Epoch 9/25\n",
      "720/720 [==============================] - 0s 106us/step - loss: 0.0848 - acc: 0.8569 - val_loss: 0.1130 - val_acc: 0.8111\n",
      "Epoch 10/25\n",
      "720/720 [==============================] - 0s 109us/step - loss: 0.0794 - acc: 0.8653 - val_loss: 0.1077 - val_acc: 0.8167\n",
      "Epoch 11/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "720/720 [==============================] - 0s 130us/step - loss: 0.0748 - acc: 0.8694 - val_loss: 0.1030 - val_acc: 0.8167\n",
      "Epoch 12/25\n",
      "720/720 [==============================] - 0s 117us/step - loss: 0.0708 - acc: 0.8736 - val_loss: 0.0980 - val_acc: 0.8167\n",
      "Epoch 13/25\n",
      "720/720 [==============================] - 0s 110us/step - loss: 0.0670 - acc: 0.8764 - val_loss: 0.0929 - val_acc: 0.8167\n",
      "Epoch 14/25\n",
      "720/720 [==============================] - 0s 136us/step - loss: 0.0631 - acc: 0.8764 - val_loss: 0.0875 - val_acc: 0.8167\n",
      "Epoch 15/25\n",
      "720/720 [==============================] - 0s 129us/step - loss: 0.0592 - acc: 0.8778 - val_loss: 0.0806 - val_acc: 0.8167\n",
      "Epoch 16/25\n",
      "720/720 [==============================] - 0s 115us/step - loss: 0.0549 - acc: 0.8778 - val_loss: 0.0722 - val_acc: 0.8167\n",
      "Epoch 17/25\n",
      "720/720 [==============================] - 0s 125us/step - loss: 0.0497 - acc: 0.8875 - val_loss: 0.0632 - val_acc: 0.8667\n",
      "Epoch 18/25\n",
      "720/720 [==============================] - 0s 103us/step - loss: 0.0442 - acc: 0.9139 - val_loss: 0.0551 - val_acc: 0.9111\n",
      "Epoch 19/25\n",
      "720/720 [==============================] - 0s 120us/step - loss: 0.0397 - acc: 0.9347 - val_loss: 0.0484 - val_acc: 0.9333\n",
      "Epoch 20/25\n",
      "720/720 [==============================] - 0s 119us/step - loss: 0.0355 - acc: 0.9417 - val_loss: 0.0438 - val_acc: 0.9389\n",
      "Epoch 21/25\n",
      "720/720 [==============================] - 0s 132us/step - loss: 0.0324 - acc: 0.9444 - val_loss: 0.0400 - val_acc: 0.9389\n",
      "Epoch 22/25\n",
      "720/720 [==============================] - 0s 140us/step - loss: 0.0297 - acc: 0.9472 - val_loss: 0.0368 - val_acc: 0.9389\n",
      "Epoch 23/25\n",
      "720/720 [==============================] - 0s 105us/step - loss: 0.0274 - acc: 0.9500 - val_loss: 0.0336 - val_acc: 0.9389\n",
      "Epoch 24/25\n",
      "720/720 [==============================] - 0s 109us/step - loss: 0.0251 - acc: 0.9556 - val_loss: 0.0309 - val_acc: 0.9389\n",
      "Epoch 25/25\n",
      "720/720 [==============================] - 0s 108us/step - loss: 0.0229 - acc: 0.9569 - val_loss: 0.0283 - val_acc: 0.9556\n",
      "232/232 [==============================] - 0s 39us/step\n",
      "('Accuracy:', 96.55172413793103)\n",
      "Confusion Matrix\n",
      "[[156   0   0]\n",
      " [  0  43   0]\n",
      " [  0   8  25]]\n",
      "('Precision(Normal)', 1.0)\n",
      "('Precision(DOS)', 0.8431372549019608)\n",
      "('Precision(Probe)', 1.0)\n"
     ]
    }
   ],
   "source": [
    "# Deep stacked auto encoder\n",
    "ly_1= autoenc_1.layers[1].get_weights()\n",
    "ly_2= autoenc_2.layers[1].get_weights()\n",
    "ly_3= autoenc_3.layers[1].get_weights()\n",
    "\n",
    "inputSAE= Input(shape=(14,))\n",
    "hid_1= Dense(7, activation='relu', input_shape=(14,), name=\"layer1\")(inputSAE)\n",
    "hid_2= Dense(5, activation='relu',name=\"layer2\")(hid_1)\n",
    "hid_3= Dense(3, activation='softmax',)(hid_2)\n",
    "hid_4= Dense(5, activation='relu',)(hid_3)\n",
    "hid_5= Dense(7, activation='relu',)(hid_4)\n",
    "hid_6= Dense(14, activation='relu',)(hid_5)\n",
    "\n",
    "model= Model(inputSAE, hid_6)\n",
    "SAE= Model(inputSAE, hid_3)\n",
    "\n",
    "model.layers[1].set_weights(ly_1) # first dense layer\n",
    "model.layers[2].set_weights(ly_2)\n",
    "model.layers[3].set_weights(ly_3)\n",
    "\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
    "model.fit(train_data, train_data,epochs=50,shuffle=True,verbose=1, validation_split=0.2)\n",
    "\n",
    "SAE.compile(optimizer='adam', loss='mean_squared_error', metrics=['accuracy'])\n",
    "SAE.fit(train_data, train_label,epochs=25,shuffle=True,verbose=1, validation_split=0.2)\n",
    "scores=SAE.evaluate(test_data,test_label)\n",
    "print(\"Accuracy:\",scores[1]*100)\n",
    "pred=SAE.predict(test_data)\n",
    "cm=confusion_matrix(test_label.argmax(axis=1),pred.argmax(axis=1))\n",
    "print(\"Confusion Matrix\")\n",
    "print(cm)\n",
    "print('Precision(Normal)',(np.float(cm[0][0])/np.float(np.sum(cm[:,0]))))\n",
    "print('Precision(DOS)',(np.float(cm[1][1])/np.float(np.sum(cm[:,1]))))\n",
    "print('Precision(Probe)',(np.float(cm[2][2])/np.float(np.sum(cm[:,2]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.6",
   "language": "python",
   "name": "python3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
