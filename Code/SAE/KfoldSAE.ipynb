{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5EqatxN0YVfU"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten,Conv1D,MaxPooling1D\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.optimizers import SGD, Adam,RMSprop,Adagrad\n",
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "%matplotlib inline\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kMI8VhgCYVfc"
   },
   "outputs": [],
   "source": [
    "np.random.seed(7)\n",
    "data= np.loadtxt('norm.csv', delimiter=',', dtype='float32')\n",
    "label=np.loadtxt('encodedlabel.csv',delimiter=',',dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "LO06MQsKYVff",
    "outputId": "4d5f4f3c-293e-47e5-c1b0-27b1c584f16f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2377, 14) (2377, 3) (595, 14) (595, 3)\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data, train_label, test_label = train_test_split(data, label, test_size=0.20, random_state=42)\n",
    "print(train_data.shape, train_label.shape,test_data.shape, test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-oOpR1jlYVfj"
   },
   "outputs": [],
   "source": [
    "adam=Adam(lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "mjKryJDgYVfm",
    "outputId": "9535dfaf-98ce-4535-c446-64d671a37302"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1901 samples, validate on 476 samples\n",
      "Epoch 1/1\n",
      "1901/1901 [==============================] - 3s 1ms/step - loss: 0.0520 - val_loss: 0.0202\n",
      "(2377, 7)\n"
     ]
    }
   ],
   "source": [
    "# autoencoder layer 1\n",
    "input_1= Input(shape=(14,))\n",
    "enc_1= Dense(7, activation='relu')(input_1)\n",
    "dec_1=Dense(14, activation='relu')(enc_1)\n",
    "\n",
    "autoenc_1= Model(input_1, dec_1)\n",
    "encoder_1= Model(input_1, enc_1)\n",
    "\n",
    "autoenc_1.compile(optimizer=adam, loss='mean_squared_error')\n",
    "autoenc_1.fit(train_data,train_data,epochs=1,validation_split=0.2)\n",
    "\n",
    "\n",
    "ly1_predict= encoder_1.predict(train_data)\n",
    "print(ly1_predict.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "Wb1--DxKYVfq",
    "outputId": "746b803b-c71e-4592-ba13-5adaad3f9491"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1901 samples, validate on 476 samples\n",
      "Epoch 1/1\n",
      "1901/1901 [==============================] - 2s 1ms/step - loss: 0.0348 - val_loss: 0.0221\n",
      "(2377, 5)\n"
     ]
    }
   ],
   "source": [
    "# autoencoder layer 2\n",
    "input_2= Input(shape=(7,))\n",
    "enc_2= Dense(5, activation='relu')(input_2)\n",
    "dec_2=Dense(7, activation='relu')(enc_2)\n",
    "\n",
    "autoenc_2= Model(input_2, dec_2)\n",
    "encoder_2= Model(input_2, enc_2)\n",
    "\n",
    "autoenc_2.compile(optimizer=adam, loss='mean_squared_error')\n",
    "autoenc_2.fit(ly1_predict,ly1_predict,epochs=1,validation_split=0.2)\n",
    "\n",
    "\n",
    "ly2_predict= encoder_2.predict(ly1_predict)\n",
    "print(ly2_predict.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "ODpVJXB5YVft",
    "outputId": "f12bfdde-3e9c-4712-b975-79fb97bc96e7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1901 samples, validate on 476 samples\n",
      "Epoch 1/1\n",
      "1901/1901 [==============================] - 2s 1ms/step - loss: 0.0280 - val_loss: 0.0057\n",
      "(2377, 3)\n"
     ]
    }
   ],
   "source": [
    "# autencoder layer 3\n",
    "input_3= Input(shape=(5,))\n",
    "enc_3= Dense(3, activation='relu')(input_3)\n",
    "dec_3=Dense(5, activation='relu')(enc_3)\n",
    "\n",
    "autoenc_3= Model(input_3, dec_3)\n",
    "encoder_3= Model(input_3, enc_3)\n",
    "\n",
    "autoenc_3.compile(optimizer=adam, loss='mean_squared_error')\n",
    "autoenc_3.fit(ly2_predict,ly2_predict,epochs=1,validation_split=0.2)\n",
    "\n",
    "\n",
    "ly3_predict= encoder_3.predict(ly2_predict)\n",
    "print(ly3_predict.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "6it26ZdYYVfw",
    "outputId": "193ec8b9-780f-46aa-ebc5-561b0aeb4c97",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1901 samples, validate on 476 samples\n",
      "Epoch 1/5\n",
      "1901/1901 [==============================] - 3s 1ms/step - loss: 0.0573 - acc: 0.6765 - val_loss: 0.0445 - val_acc: 0.6534\n",
      "Epoch 2/5\n",
      "1901/1901 [==============================] - 0s 61us/step - loss: 0.0430 - acc: 0.6749 - val_loss: 0.0430 - val_acc: 0.6534\n",
      "Epoch 3/5\n",
      "1901/1901 [==============================] - 0s 66us/step - loss: 0.0427 - acc: 0.6749 - val_loss: 0.0431 - val_acc: 0.6534\n",
      "Epoch 4/5\n",
      "1901/1901 [==============================] - 0s 61us/step - loss: 0.0425 - acc: 0.6623 - val_loss: 0.0426 - val_acc: 0.6534\n",
      "Epoch 5/5\n",
      "1901/1901 [==============================] - 0s 62us/step - loss: 0.0420 - acc: 0.6339 - val_loss: 0.0422 - val_acc: 0.6008\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe84e943b70>"
      ]
     },
     "execution_count": 63,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Deep stacked auto encoder\n",
    "ly_1= autoenc_1.layers[1].get_weights()\n",
    "ly_2= autoenc_2.layers[1].get_weights()\n",
    "ly_3= autoenc_3.layers[1].get_weights()\n",
    "\n",
    "inputSAE= Input(shape=(14,))\n",
    "hid_1= Dense(7, activation='relu', input_shape=(14,), name=\"layer1\")(inputSAE)\n",
    "hid_2= Dense(5, activation='relu',name=\"layer2\")(hid_1)\n",
    "hid_3= Dense(3, activation='softmax',)(hid_2)\n",
    "hid_4= Dense(5, activation='relu',)(hid_3)\n",
    "hid_5= Dense(7, activation='relu',)(hid_4)\n",
    "hid_6= Dense(14, activation='relu',)(hid_5)\n",
    "\n",
    "model= Model(inputSAE, hid_6)\n",
    "SAE= Model(inputSAE, hid_3)\n",
    "\n",
    "model.layers[1].set_weights(ly_1) # first dense layer\n",
    "model.layers[2].set_weights(ly_2)\n",
    "model.layers[3].set_weights(ly_3)\n",
    "\n",
    "\n",
    "model.compile(optimizer=adam, loss='mean_squared_error', metrics=['accuracy'])\n",
    "model.fit(train_data, train_data,epochs=5,shuffle=True, validation_split=0.2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vVq3QXjsYVfz"
   },
   "outputs": [],
   "source": [
    "train_data.shape\n",
    "train_label.shape\n",
    "Accu=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 6443
    },
    "colab_type": "code",
    "id": "h-JL2CkOYVf2",
    "outputId": "b72026e0-5faf-4ec5-d283-09d45b8a1100",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold KFold(n_splits=6, random_state=1, shuffle=False)\n",
      "train: [[5.4195714e-01 5.2941179e-01 0.0000000e+00 ... 1.2532900e-04\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [6.1931187e-01 2.1568628e-01 1.3117764e-04 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [9.1090423e-01 5.3431374e-01 6.9481522e-01 ... 3.3421064e-04\n",
      "  6.8775791e-04 1.2923624e-05]\n",
      " ...\n",
      " [5.4195714e-01 5.2941179e-01 0.0000000e+00 ... 1.2532900e-04\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [6.1931187e-01 7.1568626e-01 1.3117764e-04 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [5.4195750e-01 5.2941179e-01 0.0000000e+00 ... 1.2532900e-04\n",
      "  0.0000000e+00 0.0000000e+00]], test: [[9.8323835e-07 5.2941179e-01 7.5528812e-01 ... 7.9375028e-04\n",
      "  6.8775791e-04 1.6800712e-05]\n",
      " [9.1090423e-01 5.3921568e-01 7.1967340e-01 ... 3.3421064e-04\n",
      "  6.8775791e-04 1.2923624e-05]\n",
      " [9.9921209e-01 5.2941179e-01 5.4822421e-01 ... 2.1907507e-01\n",
      "  2.1595599e-01 3.4912783e-01]\n",
      " ...\n",
      " [9.1098565e-01 5.2941179e-01 6.3985175e-01 ... 2.5065799e-04\n",
      "  6.8775791e-04 1.6800712e-05]\n",
      " [9.1090423e-01 5.3921568e-01 8.3668381e-01 ... 3.3421064e-04\n",
      "  6.8775791e-04 1.2923624e-05]\n",
      " [6.1931187e-01 3.6764705e-01 1.3117764e-04 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]]\n",
      "Train on 1980 samples, validate on 496 samples\n",
      "Epoch 1/10\n",
      "1980/1980 [==============================] - 3s 1ms/step - loss: 0.1681 - acc: 0.7101 - val_loss: 0.0930 - val_acc: 0.8448\n",
      "Epoch 2/10\n",
      "1980/1980 [==============================] - 0s 55us/step - loss: 0.0739 - acc: 0.8707 - val_loss: 0.0586 - val_acc: 0.9032\n",
      "Epoch 3/10\n",
      "1980/1980 [==============================] - 0s 56us/step - loss: 0.0612 - acc: 0.8939 - val_loss: 0.0520 - val_acc: 0.9052\n",
      "Epoch 4/10\n",
      "1980/1980 [==============================] - 0s 54us/step - loss: 0.0552 - acc: 0.9086 - val_loss: 0.0455 - val_acc: 0.9456\n",
      "Epoch 5/10\n",
      "1980/1980 [==============================] - 0s 54us/step - loss: 0.0472 - acc: 0.9298 - val_loss: 0.0408 - val_acc: 0.9274\n",
      "Epoch 6/10\n",
      "1980/1980 [==============================] - 0s 55us/step - loss: 0.0446 - acc: 0.9364 - val_loss: 0.0363 - val_acc: 0.9516\n",
      "Epoch 7/10\n",
      "1980/1980 [==============================] - 0s 54us/step - loss: 0.0409 - acc: 0.9424 - val_loss: 0.0344 - val_acc: 0.9536\n",
      "Epoch 8/10\n",
      "1980/1980 [==============================] - 0s 56us/step - loss: 0.0393 - acc: 0.9434 - val_loss: 0.0333 - val_acc: 0.9536\n",
      "Epoch 9/10\n",
      "1980/1980 [==============================] - 0s 55us/step - loss: 0.0385 - acc: 0.9455 - val_loss: 0.0330 - val_acc: 0.9536\n",
      "Epoch 10/10\n",
      "1980/1980 [==============================] - 0s 55us/step - loss: 0.0375 - acc: 0.9460 - val_loss: 0.0321 - val_acc: 0.9536\n",
      "496/496 [==============================] - 0s 44us/step\n",
      "Accuracy: 93.75\n",
      "Confusion Matrix\n",
      "[[163   0   1]\n",
      " [  1 165   1]\n",
      " [  0  28 137]]\n",
      "Precision(Normal) 0.9939024390243902\n",
      "Precision(DOS) 0.8549222797927462\n",
      "Precision(Probe) 0.9856115107913669\n",
      "Recall(Normal) 0.9939024390243902\n",
      "Recall(DOS) 0.9880239520958084\n",
      "Recall(Probe) 0.8303030303030303\n",
      "FScore(Normal) 0.9939024390243902\n",
      "FScore(DOS) 0.9166666666666666\n",
      "FScore(Probe) 0.9013157894736843\n",
      "kappa_score 0.9062175976188442\n",
      "fold KFold(n_splits=6, random_state=1, shuffle=False)\n",
      "train: [[9.8323835e-07 5.2941179e-01 7.5528812e-01 ... 7.9375028e-04\n",
      "  6.8775791e-04 1.6800712e-05]\n",
      " [9.1090423e-01 5.3921568e-01 7.1967340e-01 ... 3.3421064e-04\n",
      "  6.8775791e-04 1.2923624e-05]\n",
      " [9.9921209e-01 5.2941179e-01 5.4822421e-01 ... 2.1907507e-01\n",
      "  2.1595599e-01 3.4912783e-01]\n",
      " ...\n",
      " [5.4195714e-01 5.2941179e-01 0.0000000e+00 ... 1.2532900e-04\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [6.1931187e-01 7.1568626e-01 1.3117764e-04 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [5.4195750e-01 5.2941179e-01 0.0000000e+00 ... 1.2532900e-04\n",
      "  0.0000000e+00 0.0000000e+00]], test: [[5.4195714e-01 5.2941179e-01 0.0000000e+00 ... 1.2532900e-04\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [6.1931187e-01 2.1568628e-01 1.3117764e-04 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [9.1090423e-01 5.3431374e-01 6.9481522e-01 ... 3.3421064e-04\n",
      "  6.8775791e-04 1.2923624e-05]\n",
      " ...\n",
      " [5.4195738e-01 5.2941179e-01 0.0000000e+00 ... 1.2532900e-04\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [6.1931193e-01 4.9019608e-01 1.3117764e-04 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [8.8736057e-01 5.2941179e-01 8.4425932e-01 ... 3.3421064e-04\n",
      "  6.8775791e-04 1.2923624e-05]]\n",
      "Train on 1980 samples, validate on 496 samples\n",
      "Epoch 1/10\n",
      "1980/1980 [==============================] - 3s 1ms/step - loss: 0.0494 - acc: 0.9258 - val_loss: 0.0320 - val_acc: 0.9536\n",
      "Epoch 2/10\n",
      "1980/1980 [==============================] - 0s 54us/step - loss: 0.0386 - acc: 0.9419 - val_loss: 0.0333 - val_acc: 0.9516\n",
      "Epoch 3/10\n",
      "1980/1980 [==============================] - 0s 55us/step - loss: 0.0378 - acc: 0.9424 - val_loss: 0.0317 - val_acc: 0.9516\n",
      "Epoch 4/10\n",
      "1980/1980 [==============================] - 0s 56us/step - loss: 0.0374 - acc: 0.9444 - val_loss: 0.0316 - val_acc: 0.9516\n",
      "Epoch 5/10\n",
      "1980/1980 [==============================] - 0s 56us/step - loss: 0.0371 - acc: 0.9434 - val_loss: 0.0324 - val_acc: 0.9516\n",
      "Epoch 6/10\n",
      "1980/1980 [==============================] - 0s 54us/step - loss: 0.0361 - acc: 0.9444 - val_loss: 0.0307 - val_acc: 0.9536\n",
      "Epoch 7/10\n",
      "1980/1980 [==============================] - 0s 54us/step - loss: 0.0363 - acc: 0.9444 - val_loss: 0.0302 - val_acc: 0.9536\n",
      "Epoch 8/10\n",
      "1980/1980 [==============================] - 0s 56us/step - loss: 0.0361 - acc: 0.9460 - val_loss: 0.0320 - val_acc: 0.9516\n",
      "Epoch 9/10\n",
      "1980/1980 [==============================] - 0s 56us/step - loss: 0.0365 - acc: 0.9444 - val_loss: 0.0323 - val_acc: 0.9516\n",
      "Epoch 10/10\n",
      "1980/1980 [==============================] - 0s 56us/step - loss: 0.0359 - acc: 0.9460 - val_loss: 0.0311 - val_acc: 0.9536\n",
      "496/496 [==============================] - 0s 41us/step\n",
      "Accuracy: 95.76612903225806\n",
      "Confusion Matrix\n",
      "[[157   1   1]\n",
      " [  0 176   0]\n",
      " [  1  18 142]]\n",
      "Precision(Normal) 0.9936708860759493\n",
      "Precision(DOS) 0.9025641025641026\n",
      "Precision(Probe) 0.993006993006993\n",
      "Recall(Normal) 0.9874213836477987\n",
      "Recall(DOS) 1.0\n",
      "Recall(Probe) 0.8819875776397516\n",
      "FScore(Normal) 0.9905362776025236\n",
      "FScore(DOS) 0.9487870619946093\n",
      "FScore(Probe) 0.9342105263157895\n",
      "kappa_score 0.9363134435130327\n",
      "fold KFold(n_splits=6, random_state=1, shuffle=False)\n",
      "train: [[9.8323835e-07 5.2941179e-01 7.5528812e-01 ... 7.9375028e-04\n",
      "  6.8775791e-04 1.6800712e-05]\n",
      " [9.1090423e-01 5.3921568e-01 7.1967340e-01 ... 3.3421064e-04\n",
      "  6.8775791e-04 1.2923624e-05]\n",
      " [9.9921209e-01 5.2941179e-01 5.4822421e-01 ... 2.1907507e-01\n",
      "  2.1595599e-01 3.4912783e-01]\n",
      " ...\n",
      " [5.4195714e-01 5.2941179e-01 0.0000000e+00 ... 1.2532900e-04\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [6.1931187e-01 7.1568626e-01 1.3117764e-04 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [5.4195750e-01 5.2941179e-01 0.0000000e+00 ... 1.2532900e-04\n",
      "  0.0000000e+00 0.0000000e+00]], test: [[9.9921232e-01 5.2941179e-01 9.1906339e-01 ... 3.6439404e-02\n",
      "  4.8143053e-03 1.5101255e-03]\n",
      " [5.4195714e-01 5.2941179e-01 0.0000000e+00 ... 1.2532900e-04\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [9.1090423e-01 5.3921568e-01 8.8889253e-01 ... 3.3421064e-04\n",
      "  6.8775791e-04 1.2923624e-05]\n",
      " ...\n",
      " [9.1090423e-01 5.3431374e-01 5.6199783e-01 ... 3.3421064e-04\n",
      "  6.8775791e-04 1.2923624e-05]\n",
      " [9.9934793e-01 5.2941179e-01 7.7798182e-01 ... 3.3421064e-04\n",
      "  6.8775791e-04 1.2923624e-05]\n",
      " [9.9999970e-01 5.2941179e-01 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]]\n",
      "Train on 1981 samples, validate on 496 samples\n",
      "Epoch 1/10\n",
      "1981/1981 [==============================] - 3s 1ms/step - loss: 0.0392 - acc: 0.9389 - val_loss: 0.0356 - val_acc: 0.9456\n",
      "Epoch 2/10\n",
      "1981/1981 [==============================] - 0s 55us/step - loss: 0.0366 - acc: 0.9455 - val_loss: 0.0301 - val_acc: 0.9536\n",
      "Epoch 3/10\n",
      "1981/1981 [==============================] - 0s 56us/step - loss: 0.0351 - acc: 0.9465 - val_loss: 0.0310 - val_acc: 0.9536\n",
      "Epoch 4/10\n",
      "1981/1981 [==============================] - 0s 58us/step - loss: 0.0357 - acc: 0.9455 - val_loss: 0.0307 - val_acc: 0.9516\n",
      "Epoch 5/10\n",
      "1981/1981 [==============================] - 0s 55us/step - loss: 0.0360 - acc: 0.9455 - val_loss: 0.0298 - val_acc: 0.9516\n",
      "Epoch 6/10\n",
      "1981/1981 [==============================] - 0s 61us/step - loss: 0.0353 - acc: 0.9470 - val_loss: 0.0298 - val_acc: 0.9536\n",
      "Epoch 7/10\n",
      "1981/1981 [==============================] - 0s 58us/step - loss: 0.0352 - acc: 0.9465 - val_loss: 0.0306 - val_acc: 0.9536\n",
      "Epoch 8/10\n",
      "1981/1981 [==============================] - 0s 56us/step - loss: 0.0350 - acc: 0.9470 - val_loss: 0.0301 - val_acc: 0.9536\n",
      "Epoch 9/10\n",
      "1981/1981 [==============================] - 0s 56us/step - loss: 0.0352 - acc: 0.9465 - val_loss: 0.0307 - val_acc: 0.9536\n",
      "Epoch 10/10\n",
      "1981/1981 [==============================] - 0s 54us/step - loss: 0.0350 - acc: 0.9470 - val_loss: 0.0297 - val_acc: 0.9536\n",
      "495/495 [==============================] - 0s 42us/step\n",
      "Accuracy: 95.5555555675969\n",
      "Confusion Matrix\n",
      "[[172   2   2]\n",
      " [  2 147   0]\n",
      " [  0  16 154]]\n",
      "Precision(Normal) 0.9885057471264368\n",
      "Precision(DOS) 0.8909090909090909\n",
      "Precision(Probe) 0.9871794871794872\n",
      "Recall(Normal) 0.9772727272727273\n",
      "Recall(DOS) 0.9865771812080537\n",
      "Recall(Probe) 0.9058823529411765\n",
      "FScore(Normal) 0.9828571428571428\n",
      "FScore(DOS) 0.9363057324840764\n",
      "FScore(Probe) 0.9447852760736197\n",
      "kappa_score 0.9333112874779541\n",
      "fold KFold(n_splits=6, random_state=1, shuffle=False)\n",
      "train: [[9.8323835e-07 5.2941179e-01 7.5528812e-01 ... 7.9375028e-04\n",
      "  6.8775791e-04 1.6800712e-05]\n",
      " [9.1090423e-01 5.3921568e-01 7.1967340e-01 ... 3.3421064e-04\n",
      "  6.8775791e-04 1.2923624e-05]\n",
      " [9.9921209e-01 5.2941179e-01 5.4822421e-01 ... 2.1907507e-01\n",
      "  2.1595599e-01 3.4912783e-01]\n",
      " ...\n",
      " [5.4195714e-01 5.2941179e-01 0.0000000e+00 ... 1.2532900e-04\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [6.1931187e-01 7.1568626e-01 1.3117764e-04 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [5.4195750e-01 5.2941179e-01 0.0000000e+00 ... 1.2532900e-04\n",
      "  0.0000000e+00 0.0000000e+00]], test: [[9.9935156e-01 5.3921568e-01 6.4224577e-01 ... 3.3421064e-04\n",
      "  6.8775791e-04 1.2923624e-05]\n",
      " [5.4195714e-01 5.2941179e-01 0.0000000e+00 ... 1.2532900e-04\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [9.1090423e-01 5.3431374e-01 6.8343556e-01 ... 3.3421064e-04\n",
      "  6.8775791e-04 1.2923624e-05]\n",
      " ...\n",
      " [9.9935162e-01 5.3921568e-01 9.1122550e-01 ... 3.3421064e-04\n",
      "  6.8775791e-04 1.2923624e-05]\n",
      " [1.3888880e-06 5.2941179e-01 9.7701114e-01 ... 5.4309226e-04\n",
      "  2.7510317e-03 7.2049203e-05]\n",
      " [5.4195714e-01 5.2941179e-01 0.0000000e+00 ... 1.2532900e-04\n",
      "  0.0000000e+00 0.0000000e+00]]\n",
      "Train on 1981 samples, validate on 496 samples\n",
      "Epoch 1/10\n",
      "1981/1981 [==============================] - 3s 1ms/step - loss: 0.0447 - acc: 0.9288 - val_loss: 0.0304 - val_acc: 0.9536\n",
      "Epoch 2/10\n",
      "1981/1981 [==============================] - 0s 56us/step - loss: 0.0346 - acc: 0.9470 - val_loss: 0.0296 - val_acc: 0.9536\n",
      "Epoch 3/10\n",
      "1981/1981 [==============================] - 0s 58us/step - loss: 0.0344 - acc: 0.9485 - val_loss: 0.0303 - val_acc: 0.9536\n",
      "Epoch 4/10\n",
      "1981/1981 [==============================] - 0s 57us/step - loss: 0.0346 - acc: 0.9470 - val_loss: 0.0302 - val_acc: 0.9536\n",
      "Epoch 5/10\n",
      "1981/1981 [==============================] - 0s 56us/step - loss: 0.0346 - acc: 0.9465 - val_loss: 0.0293 - val_acc: 0.9536\n",
      "Epoch 6/10\n",
      "1981/1981 [==============================] - 0s 58us/step - loss: 0.0351 - acc: 0.9460 - val_loss: 0.0312 - val_acc: 0.9536\n",
      "Epoch 7/10\n",
      "1981/1981 [==============================] - 0s 54us/step - loss: 0.0352 - acc: 0.9460 - val_loss: 0.0299 - val_acc: 0.9516\n",
      "Epoch 8/10\n",
      "1981/1981 [==============================] - 0s 60us/step - loss: 0.0348 - acc: 0.9460 - val_loss: 0.0304 - val_acc: 0.9516\n",
      "Epoch 9/10\n",
      "1981/1981 [==============================] - 0s 56us/step - loss: 0.0346 - acc: 0.9475 - val_loss: 0.0304 - val_acc: 0.9536\n",
      "Epoch 10/10\n",
      "1981/1981 [==============================] - 0s 57us/step - loss: 0.0341 - acc: 0.9475 - val_loss: 0.0297 - val_acc: 0.9536\n",
      "495/495 [==============================] - 0s 45us/step\n",
      "Accuracy: 95.15151515151516\n",
      "Confusion Matrix\n",
      "[[170   0   4]\n",
      " [  0 151   0]\n",
      " [  0  20 150]]\n",
      "Precision(Normal) 1.0\n",
      "Precision(DOS) 0.8830409356725146\n",
      "Precision(Probe) 0.974025974025974\n",
      "Recall(Normal) 0.9770114942528736\n",
      "Recall(DOS) 1.0\n",
      "Recall(Probe) 0.8823529411764706\n",
      "FScore(Normal) 0.9883720930232558\n",
      "FScore(DOS) 0.937888198757764\n",
      "FScore(Probe) 0.9259259259259258\n",
      "kappa_score 0.9273145542204058\n",
      "fold KFold(n_splits=6, random_state=1, shuffle=False)\n",
      "train: [[9.8323835e-07 5.2941179e-01 7.5528812e-01 ... 7.9375028e-04\n",
      "  6.8775791e-04 1.6800712e-05]\n",
      " [9.1090423e-01 5.3921568e-01 7.1967340e-01 ... 3.3421064e-04\n",
      "  6.8775791e-04 1.2923624e-05]\n",
      " [9.9921209e-01 5.2941179e-01 5.4822421e-01 ... 2.1907507e-01\n",
      "  2.1595599e-01 3.4912783e-01]\n",
      " ...\n",
      " [5.4195714e-01 5.2941179e-01 0.0000000e+00 ... 1.2532900e-04\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [6.1931187e-01 7.1568626e-01 1.3117764e-04 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [5.4195750e-01 5.2941179e-01 0.0000000e+00 ... 1.2532900e-04\n",
      "  0.0000000e+00 0.0000000e+00]], test: [[6.1931193e-01 2.3039216e-01 1.3117764e-04 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [9.9924582e-01 5.2941179e-01 5.8610171e-01 ... 1.0861845e-03\n",
      "  1.3755158e-03 4.3617230e-05]\n",
      " [5.4195714e-01 5.2941179e-01 0.0000000e+00 ... 1.2532900e-04\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " ...\n",
      " [9.9920869e-01 5.2941179e-01 6.3611323e-01 ... 1.6292769e-03\n",
      "  2.0632737e-03 6.0417944e-05]\n",
      " [9.1090423e-01 5.3921568e-01 5.7757521e-01 ... 3.3421064e-04\n",
      "  6.8775791e-04 1.2923624e-05]\n",
      " [1.0000000e+00 5.2941179e-01 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]]\n",
      "Train on 1981 samples, validate on 496 samples\n",
      "Epoch 1/10\n",
      "1981/1981 [==============================] - 3s 1ms/step - loss: 0.0361 - acc: 0.9435 - val_loss: 0.0330 - val_acc: 0.9476\n",
      "Epoch 2/10\n",
      "1981/1981 [==============================] - 0s 57us/step - loss: 0.0316 - acc: 0.9520 - val_loss: 0.0312 - val_acc: 0.9556\n",
      "Epoch 3/10\n",
      "1981/1981 [==============================] - 0s 56us/step - loss: 0.0333 - acc: 0.9485 - val_loss: 0.0301 - val_acc: 0.9516\n",
      "Epoch 4/10\n",
      "1981/1981 [==============================] - 0s 58us/step - loss: 0.0310 - acc: 0.9531 - val_loss: 0.0302 - val_acc: 0.9516\n",
      "Epoch 5/10\n",
      "1981/1981 [==============================] - 0s 59us/step - loss: 0.0309 - acc: 0.9536 - val_loss: 0.0311 - val_acc: 0.9536\n",
      "Epoch 6/10\n",
      "1981/1981 [==============================] - 0s 57us/step - loss: 0.0310 - acc: 0.9536 - val_loss: 0.0314 - val_acc: 0.9536\n",
      "Epoch 7/10\n",
      "1981/1981 [==============================] - 0s 57us/step - loss: 0.0309 - acc: 0.9531 - val_loss: 0.0309 - val_acc: 0.9516\n",
      "Epoch 8/10\n",
      "1981/1981 [==============================] - 0s 56us/step - loss: 0.0308 - acc: 0.9536 - val_loss: 0.0309 - val_acc: 0.9516\n",
      "Epoch 9/10\n",
      "1981/1981 [==============================] - 0s 56us/step - loss: 0.0310 - acc: 0.9525 - val_loss: 0.0315 - val_acc: 0.9516\n",
      "Epoch 10/10\n",
      "1981/1981 [==============================] - 0s 59us/step - loss: 0.0312 - acc: 0.9520 - val_loss: 0.0302 - val_acc: 0.9516\n",
      "495/495 [==============================] - 0s 43us/step\n",
      "Accuracy: 92.92929292929293\n",
      "Confusion Matrix\n",
      "[[149   0   3]\n",
      " [  2 161   0]\n",
      " [  2  28 150]]\n",
      "Precision(Normal) 0.9738562091503268\n",
      "Precision(DOS) 0.8518518518518519\n",
      "Precision(Probe) 0.9803921568627451\n",
      "Recall(Normal) 0.9802631578947368\n",
      "Recall(DOS) 0.9877300613496932\n",
      "Recall(Probe) 0.8333333333333334\n",
      "FScore(Normal) 0.9770491803278688\n",
      "FScore(DOS) 0.9147727272727273\n",
      "FScore(Probe) 0.9009009009009009\n",
      "kappa_score 0.8939861218195837\n",
      "fold KFold(n_splits=6, random_state=1, shuffle=False)\n",
      "train: [[9.8323835e-07 5.2941179e-01 7.5528812e-01 ... 7.9375028e-04\n",
      "  6.8775791e-04 1.6800712e-05]\n",
      " [9.1090423e-01 5.3921568e-01 7.1967340e-01 ... 3.3421064e-04\n",
      "  6.8775791e-04 1.2923624e-05]\n",
      " [9.9921209e-01 5.2941179e-01 5.4822421e-01 ... 2.1907507e-01\n",
      "  2.1595599e-01 3.4912783e-01]\n",
      " ...\n",
      " [9.9920869e-01 5.2941179e-01 6.3611323e-01 ... 1.6292769e-03\n",
      "  2.0632737e-03 6.0417944e-05]\n",
      " [9.1090423e-01 5.3921568e-01 5.7757521e-01 ... 3.3421064e-04\n",
      "  6.8775791e-04 1.2923624e-05]\n",
      " [1.0000000e+00 5.2941179e-01 0.0000000e+00 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]], test: [[9.9924594e-01 5.2941179e-01 5.8695436e-01 ... 2.1173288e-01\n",
      "  1.8775791e-01 3.3304116e-01]\n",
      " [9.9933410e-01 5.3921568e-01 9.2900008e-01 ... 3.3421064e-04\n",
      "  6.8775791e-04 1.2923624e-05]\n",
      " [9.1090423e-01 5.3431374e-01 5.9689111e-01 ... 3.3421064e-04\n",
      "  6.8775791e-04 1.2923624e-05]\n",
      " ...\n",
      " [5.4195714e-01 5.2941179e-01 0.0000000e+00 ... 1.2532900e-04\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [6.1931187e-01 7.1568626e-01 1.3117764e-04 ... 0.0000000e+00\n",
      "  0.0000000e+00 0.0000000e+00]\n",
      " [5.4195750e-01 5.2941179e-01 0.0000000e+00 ... 1.2532900e-04\n",
      "  0.0000000e+00 0.0000000e+00]]\n",
      "Train on 1981 samples, validate on 496 samples\n",
      "Epoch 1/10\n",
      "1981/1981 [==============================] - 3s 2ms/step - loss: 0.0345 - acc: 0.9465 - val_loss: 0.0487 - val_acc: 0.9234\n",
      "Epoch 2/10\n",
      "1981/1981 [==============================] - 0s 56us/step - loss: 0.0316 - acc: 0.9520 - val_loss: 0.0479 - val_acc: 0.9254\n",
      "Epoch 3/10\n",
      "1981/1981 [==============================] - 0s 57us/step - loss: 0.0312 - acc: 0.9531 - val_loss: 0.0481 - val_acc: 0.9234\n",
      "Epoch 4/10\n",
      "1981/1981 [==============================] - 0s 58us/step - loss: 0.0310 - acc: 0.9531 - val_loss: 0.0463 - val_acc: 0.9274\n",
      "Epoch 5/10\n",
      "1981/1981 [==============================] - 0s 57us/step - loss: 0.0321 - acc: 0.9515 - val_loss: 0.0477 - val_acc: 0.9254\n",
      "Epoch 6/10\n",
      "1981/1981 [==============================] - 0s 65us/step - loss: 0.0312 - acc: 0.9520 - val_loss: 0.0463 - val_acc: 0.9274\n",
      "Epoch 7/10\n",
      "1981/1981 [==============================] - 0s 63us/step - loss: 0.0309 - acc: 0.9531 - val_loss: 0.0462 - val_acc: 0.9274\n",
      "Epoch 8/10\n",
      "1981/1981 [==============================] - 0s 58us/step - loss: 0.0310 - acc: 0.9525 - val_loss: 0.0470 - val_acc: 0.9274\n",
      "Epoch 9/10\n",
      "1981/1981 [==============================] - 0s 57us/step - loss: 0.0313 - acc: 0.9525 - val_loss: 0.0464 - val_acc: 0.9294\n",
      "Epoch 10/10\n",
      "1981/1981 [==============================] - 0s 58us/step - loss: 0.0315 - acc: 0.9520 - val_loss: 0.0459 - val_acc: 0.9274\n",
      "495/495 [==============================] - 0s 45us/step\n",
      "Accuracy: 95.15151515151516\n",
      "Confusion Matrix\n",
      "[[143   1   1]\n",
      " [  3 179   2]\n",
      " [  0  17 149]]\n",
      "Precision(Normal) 0.9794520547945206\n",
      "Precision(DOS) 0.9086294416243654\n",
      "Precision(Probe) 0.9802631578947368\n",
      "Recall(Normal) 0.9862068965517241\n",
      "Recall(DOS) 0.9728260869565217\n",
      "Recall(Probe) 0.8975903614457831\n",
      "FScore(Normal) 0.9828178694158075\n",
      "FScore(DOS) 0.9396325459317585\n",
      "FScore(Probe) 0.9371069182389937\n",
      "kappa_score 0.9268360277136258\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "kfold = KFold(6, False, 1)\n",
    "for train, test in kfold.split(data):\n",
    "    print('fold',kfold)\n",
    "    print('train: %s, test: %s' % (data[train], data[test]))\n",
    "    train_data= data[train]\n",
    "    test_data= data[test]\n",
    "    train_label=label[train]\n",
    "    test_label=label[test]\n",
    "    SAE.compile(optimizer=adam, loss='mean_squared_error', metrics=['accuracy'])\n",
    "    history=SAE.fit(train_data, train_label,epochs=10,shuffle=True, validation_split=0.2)\n",
    "    scores=SAE.evaluate(test_data,test_label)\n",
    "    print(\"Accuracy:\",scores[1]*100)\n",
    "    pred=SAE.predict(test_data)\n",
    "    cm=confusion_matrix(test_label.argmax(axis=1),pred.argmax(axis=1))\n",
    "    print(\"Confusion Matrix\")\n",
    "    print(cm)\n",
    "    PN=(np.float(cm[0][0])/np.float(np.sum(cm[:,0])))\n",
    "    PD=(np.float(cm[1][1])/np.float(np.sum(cm[:,1])))\n",
    "    PP=(np.float(cm[2][2])/np.float(np.sum(cm[:,2])))\n",
    "\n",
    "    print('Precision(Normal)',PN)\n",
    "    print('Precision(DOS)',PD)\n",
    "    print('Precision(Probe)',PP)\n",
    "\n",
    "    RN=(np.float(cm[0][0])/np.float(np.sum(cm[0,:])))\n",
    "    RD=(np.float(cm[1][1])/np.float(np.sum(cm[1,:])))\n",
    "    RP=(np.float(cm[2][2])/np.float(np.sum(cm[2,:])))\n",
    "    print('Recall(Normal)',RN)\n",
    "    print('Recall(DOS)',RD)\n",
    "    print('Recall(Probe)',RP)\n",
    "\n",
    "    FSN=2*(PN*RN)/(PN+RN)\n",
    "    FSD=2*(PD*RD)/(PD+RD)\n",
    "    FSP=2*(PP*RP)/(PP+RP)\n",
    "    print('FScore(Normal)',FSN)\n",
    "    print('FScore(DOS)',FSD)\n",
    "    print('FScore(Probe)',FSP)\n",
    "\n",
    "    kappa_score=cohen_kappa_score(test_label.argmax(axis=1),pred.argmax(axis=1))\n",
    "    print('kappa_score',kappa_score)\n",
    "    Accu.append(float(scores[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 325
    },
    "colab_type": "code",
    "id": "oBEdKoNFYVf5",
    "outputId": "98cdfed8-cc91-4b52-8176-89b82db7d776"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9375, 0.9576612903225806, 0.955555555675969, 0.9515151515151515, 0.9292929292929293, 0.9515151515151515]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEjCAYAAADdZh27AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nklQxFCRJlf8PGCkHZC3fCu8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(Accu)\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Boxplot for 6 fold for SAE', fontsize=14, fontweight='bold')\n",
    "\n",
    "ax = fig.add_subplot(111)\n",
    "ax.boxplot(Accu)\n",
    "ax.set_xlabel('SAE')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set(ylim=(.85, 1.00))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9pAcaA0DYVgC"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "KfoldSAE.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
